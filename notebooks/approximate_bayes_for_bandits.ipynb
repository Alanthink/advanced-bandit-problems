{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# approximate_bayes_for_bandits\n",
    "\n",
    "## Approximate bayesian inference for gaussian bandits\n",
    "\n",
    "Let us experiment with different techniques for approximate bayesian inference aiming at using Thomspon Sampling to solve bandit problems, drawing inspiration from the paper [\"A Tutorial on Thompson Sampling\"](https://web.stanford.edu/~bvr/pubs/TS_Tutorial.pdf), mainly from the ideas on section 5. Let us test the algorithms on a simple bandit with gaussian rewards, such that we can compare our approximate inference techniques with the exact solution, obatined through a conjugate prior. I'll implement and compare the following approximation techniques:\n",
    "\n",
    "1. **Exact inference**, where we use a conjugate prior to analytically update the posterior\n",
    "2. **MCMC sampling**, where we approximate the posterior by an empirical distribution obtained through the Metropolis-Hastings algorithm\n",
    "3. **Variational Inference**, where we approximate the posterior by trying to match it to an arbitrarily chosen variational distribution\n",
    "4. **Bootstrapping**, where we approximate the posterior by an empirical distribution obtained through bootstrap samples of the data\n",
    "\n",
    "## Why is this relevant?\n",
    "\n",
    "You can frame many industry problems as bandit problems. Any problem which involves experimentation and online data gathering (in the sense that you need to take some action and incur some cost in order to access it) calls for this type of treatment. Instantly, we can think of testing different layouts of a website, actively recommending new products to clients, or dynamically setting prices in an online marketplace as examples in which these techniques are useful. \n",
    "\n",
    "More often than not we are presented with problems such that we cannot calculate posterior distributions for our quantities of interest analytically. However, there are ways to get reasonable approximations to posteriors. In this post, we aim to implement and test some of these approximations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting inline but with a non-gui backend\n",
    "#import matplotlib as mpl; mpl.use('Agg')\n",
    "%matplotlib inline\n",
    "\n",
    "# importing necessary modules\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import edward as ed\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "#import pymc3 as pm\n",
    "from tqdm import tqdm\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.stats import norm as norm_dist\n",
    "from edward.models import Normal, Empirical\n",
    "from edward.inferences import MetropolisHastings, ReparameterizationEntropyKLqp\n",
    "\n",
    "# importing things from autograd\n",
    "import autograd.numpy as agnp\n",
    "import autograd.numpy.random as agnpr\n",
    "import autograd.scipy.stats.norm as agnorm\n",
    "from autograd import grad\n",
    "from autograd.misc.optimizers import adam, sgd, rmsprop\n",
    "\n",
    "# turning off automatic plot showing, and setting style\n",
    "plt.style.use('bmh')\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gaussian Bandit\n",
    "\n",
    "Let us change up a bit from previous posts and experiment with bandits that produce continuous-valued rewards. We'll choose the Gaussian distribution as ground-truth for generating rewards. Thus, each bandit $k$ can be modeled as a random variable $Y_k \\sim \\mathcal{N}(\\mu_k, \\sigma_k^2)$. The code that implements this bandit game is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for our row of bandits\n",
    "class GaussianMAB:\n",
    "    \n",
    "    # initialization\n",
    "    def __init__(self, mu, sigma):\n",
    "        \n",
    "        # storing mean and standard deviation vectors\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    # function that helps us draw from the bandits\n",
    "    def draw(self, k):\n",
    "\n",
    "        # we return the reward and the regret of the action\n",
    "        return np.random.normal(self.mu[k], self.sigma[k]), np.max(self.mu) - self.mu[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance of our newly implemented MAB\n",
    "gmab = GaussianMAB([0.0,-0.30,-0.15,0.30,0.15], [0.3]*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of rewards for each bandit is shown below. At each round, the player chooses one bandit $k$ and receives a reward according to one of the distributions $Y_k \\sim \\mathcal{N}(\\mu_k, \\sigma_k^2)$. As we want to focus on approximate inference, the problem is simplified so all the reward distributions have the same stardard deviation. I'll explore reward distributions of different risks in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening figure \n",
    "fig = plt.figure(figsize=(10,4), dpi=150)\n",
    "\n",
    "# our grid values\n",
    "x_grid = np.linspace(-1.5, 1.5, 100)\n",
    "\n",
    "# colors for each bandit\n",
    "bandit_colors = ['red', 'green', 'blue', 'purple', 'orange']\n",
    "\n",
    "# plotting the distributions\n",
    "for i in range(len(gmab.mu)):\n",
    "    \n",
    "    # generating the density\n",
    "    dens = norm_dist(gmab.mu[i], gmab.sigma[i]).pdf(x_grid)\n",
    "    \n",
    "    # plotting and filling\n",
    "    plt.plot(x_grid, dens, color=bandit_colors[i], label='Bandit {}'.format(i), alpha=0.5)\n",
    "    plt.fill_between(x_grid, dens, color=bandit_colors[i], alpha=0.5)\n",
    "    \n",
    "# adding legend and titles\n",
    "plt.legend()\n",
    "plt.title('Reward distributions for the bandits')\n",
    "plt.xlabel('$x$'); plt.ylabel('Density')\n",
    "plt.tight_layout();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the usual visualization of rewards over time. In the animation, each draw is represented by a dot with size proportional to the reward. Each horizontal line represents one of five bandits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gmab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2f7cf2b06ed3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# number of bandits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mN_BANDITS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgmab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# numpy arrays for accumulating draws, bandit choices and rewards, more efficient calculations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gmab' is not defined"
     ]
    }
   ],
   "source": [
    "# number of draws\n",
    "N_DRAWS = 200\n",
    "\n",
    "# number of bandits\n",
    "N_BANDITS = len(gmab.mu)\n",
    "\n",
    "# numpy arrays for accumulating draws, bandit choices and rewards, more efficient calculations\n",
    "k_array = np.zeros((N_BANDITS,N_DRAWS))\n",
    "reward_array = np.zeros((N_BANDITS,N_DRAWS))\n",
    "\n",
    "# lists for ease of use, visualization\n",
    "k_list = []\n",
    "reward_list = []\n",
    "\n",
    "# opening figure and setting style\n",
    "fig, ax = plt.subplots(figsize=(9, 3), dpi=150)\n",
    "\n",
    "# colors for each bandit\n",
    "bandit_colors = ['red', 'green', 'blue', 'purple', 'orange']\n",
    "\n",
    "# loop generating draws\n",
    "for draw_number in range(N_DRAWS):\n",
    "    \n",
    "    # choosing arm and drawing\n",
    "    k = np.random.choice(range(N_BANDITS),1)[0]\n",
    "    reward, regret = gmab.draw(k)\n",
    "    \n",
    "    # record information about this draw\n",
    "    k_list.append(k)\n",
    "    reward_list.append(reward)\n",
    "    k_array[k, draw_number] = 1\n",
    "    reward_array[k, draw_number] = reward\n",
    "      \n",
    "    # getting list of colors that tells us the bandit\n",
    "    color_list = [bandit_colors[k] for k in k_list]\n",
    "        \n",
    "# initializing with first data\n",
    "ax.scatter(y=[k_list[0]], x=[list(range(N_DRAWS))[0]], color=[color_list[0]], linestyle='-', marker='o', s=40*(np.clip(reward_list[0], -0.9, 0.9) + 0.9));\n",
    "\n",
    "# titles\n",
    "ax.set_title('Random draws from the Gaussian bandits', fontsize=10);\n",
    "ax.set_xlabel('Round', fontsize=10); plt.ylabel('Bandit', fontsize=10);\n",
    "ax.set_yticks(list(range(N_BANDITS)));\n",
    "ax.set_yticklabels(['{}\\n($\\\\mu = {}$)'.format(i, gmab.mu[i]) for i in range(N_BANDITS)]);\n",
    "ax.set(xlim=(-1, N_DRAWS), ylim=(-0.5, N_BANDITS-0.5))\n",
    "ax.tick_params(labelsize=10);\n",
    "\n",
    "# function for updating\n",
    "def animate(i):\n",
    "    \n",
    "    # clearing plot\n",
    "    ax.clear()\n",
    "    \n",
    "    # initializing with first data\n",
    "    ax.scatter(y=k_list[:i], x=list(range(N_DRAWS))[:i], \n",
    "               color=color_list[:i], linestyle='-', marker='o', \n",
    "               s=40*(np.clip(reward_list[:i], -0.9, 0.9) + 0.9));\n",
    "\n",
    "    # titles\n",
    "    ax.set_title('Random draws from the Gaussian bandits', fontsize=10);\n",
    "    ax.set_xlabel('Round', fontsize=10); plt.ylabel('Bandit', fontsize=10);\n",
    "    ax.set_yticks(list(range(N_BANDITS)));\n",
    "    ax.set_yticklabels(['{}\\n($\\\\mu = {}$)'.format(i, gmab.mu[i]) for i in range(N_BANDITS)]);\n",
    "    ax.tick_params(labelsize=10);\n",
    "    ax.set(xlim=(-1, N_DRAWS), ylim=(-0.5, N_BANDITS-0.5))\n",
    "    return ()\n",
    "\n",
    "# function for creating animation\n",
    "anim = FuncAnimation(fig, animate, frames=N_DRAWS, interval=200, blit=True)\n",
    "\n",
    "# showing\n",
    "video = HTML(anim.to_html5_video())\n",
    "\n",
    "# closing figures and then showing video\n",
    "plt.close();\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool. By visual inspection, it becomes clear that Bandits 1 and 2 are not very promising, while conclusions about the others are not that immediate. So how can we model the expected rewards for each bandit as the game progresses? This is the central question in this post. Let us start with a natural baseline for comparison: **exact inference**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact inference\n",
    "\n",
    "Our goal in this tutorial is to estimate the probability distribution of the mean (or expected) rewards $\\mu_k$ for each bandit $k$ given some observations $x_k$. We can use Bayes formula to do that:\n",
    "\n",
    "$$\\large P(\\mu_k\\ |\\ x_k) = \\frac{P(x_k\\ |\\ \\mu_k) \\cdot{} P(\\mu_k)}{P(x_k)}$$\n",
    "\n",
    "If you need a refresher, $P(\\mu_k\\ |\\ x_k)$ is the posterior distribution and our quantity of interest, $P(x_k\\ |\\ \\mu_k)$ is the likelihood, $P(\\mu_k)$ is the prior and $P(x_k)$ is the model evidence. The first two quantities are easy to compute, as they depend on the parameters we want to estimate. The last quantity, the evidence $P(x_k)$ is harder, as it measures the probability of data given the model, that is, the likelihood of the data over all possible parameter choices:\n",
    "\n",
    "$$\\large P(x_k) = \\int_{\\mu_k} P(x_k\\ |\\ \\mu_k) \\, \\mathrm{d}\\mu_k$$\n",
    "\n",
    "In other settings we won't solve Bayes formula because calculating this integral is intractable, especially when we have more parameters. However, in our simple case, we can get the posterior analytically through a property called conjugacy. When the prior and posterior distributions are of the same family for a given likelihood, they're called conjugate distributions, and the prior is called a [conjugate prior](https://en.wikipedia.org/wiki/Conjugate_prior) for the likelihood function. When the data is Gaussian distributed, the prior and posterior for the mean of the data generating process are also Gaussian. To make things easier, we assume we know the standard deviation of the likelihood beforehand. We can perform this same inference with an unknown $\\sigma$, but I'll leave it to the future. We just need to calculate, for each bandit $k$, and given a prior $\\mu^0_k \\sim \\mathcal{N}(\\mu_{0_k}, \\sigma_{0_k})$, the posterior after seeing $n$ observations $\\mu^n_k$:\n",
    "\n",
    "$$\\large \\mu^n_k \\sim \\mathcal{N}\\Bigg(\\frac{1}{\\frac{1}{(\\sigma_{0_k})^2} + \\frac{n}{({\\sigma_{true_k}})^2}}\\Bigg(\\frac{\\mu_{0_k}}{(\\sigma_{0_k})^2} + \\frac{\\sum_{i=1}^n x_i}{({\\sigma_{true_k}})^2}\\Bigg),\\Bigg(\\frac{1}{(\\sigma_{0_k})^2} + \\frac{n}{({\\sigma_{true_k}})^2}\\Bigg)^{-1}\\Bigg)$$\n",
    " \n",
    "Where $\\large \\sigma_{true_k}$ is the known standard deviation of our Gaussian likelihood, for each bandit bandit $k$. We can easily implement this with a class in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for exact gaussian inference\n",
    "class ExactGaussianInference:\n",
    "    \n",
    "    # initializing with prior paramters\n",
    "    def __init__(self, prior_mu, prior_sigma, likelihood_sigma):\n",
    "        \n",
    "        # storing\n",
    "        self.prior_mu = prior_mu\n",
    "        self.prior_sigma = prior_sigma\n",
    "        self.post_mu = prior_mu\n",
    "        self.post_sigma = prior_sigma\n",
    "        self.likelihood_sigma = likelihood_sigma\n",
    "                \n",
    "    # fitting the posterior for the mean\n",
    "    def get_posterior(self, obs):\n",
    "        \n",
    "        # checking if there is any observation before proceeding\n",
    "        if len(obs) > 0:\n",
    "        \n",
    "            # calculating needed statistics for the observations\n",
    "            obs_mu = np.mean(obs)\n",
    "            obs_sum = np.sum(obs)\n",
    "            obs_n = len(obs)\n",
    "\n",
    "            # updating posterior mean\n",
    "            self.post_mu = (1/(1/self.prior_sigma**2 + obs_n/self.likelihood_sigma**2) *\n",
    "                            (self.prior_mu/self.prior_sigma**2 + obs_sum/self.likelihood_sigma**2))\n",
    "\n",
    "            # updating posterior sigma\n",
    "            self.post_sigma = (1/self.prior_sigma**2 + obs_n/self.likelihood_sigma**2)**(-1)\n",
    "            \n",
    "        # return posterior\n",
    "        return norm_dist(self.post_mu, np.sqrt(self.post_sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following animation illustrates how our exact posterior inference algorithm works. It shows 100 draws from a $\\mathcal{N}(0.2, 1.0)$ distribution, and the exact posterior distribution over its expected value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true paramters\n",
    "TRUE_MU = 0.2\n",
    "TRUE_SIGMA = 1.0\n",
    "N_ROUNDS = 100\n",
    "\n",
    "# instatating our exact inference object \n",
    "# and defining prior hyperparameters:\n",
    "infer = ExactGaussianInference(0.0, 1.0, TRUE_SIGMA)\n",
    "\n",
    "# true distribution\n",
    "true_dist = norm_dist(TRUE_MU, TRUE_SIGMA)\n",
    "\n",
    "# our grid values\n",
    "x_grid = np.linspace(-2.0, 2.0, 2000)\n",
    "\n",
    "# opening figure \n",
    "fig, ax = plt.subplots(figsize=(10, 5), dpi=150)\n",
    "\n",
    "# lists for accumulating round results\n",
    "dens_list = []\n",
    "obs_list = []\n",
    "\n",
    "# list of observations which will grow through the rounds\n",
    "obs = []\n",
    "\n",
    "# timing\n",
    "start = time.time()\n",
    "\n",
    "# loop for each round\n",
    "for round in range(N_ROUNDS):\n",
    "    \n",
    "    # updating the object with the data and getting posterior\n",
    "    posterior = infer.get_posterior(obs)\n",
    "    \n",
    "    # generating density for the posterior\n",
    "    dens = posterior.pdf(x_grid)\n",
    "    \n",
    "    # saving results in lists\n",
    "    dens_list.append(dens)\n",
    "    obs_list += [np.array(obs)]\n",
    "    \n",
    "    # generating some data\n",
    "    new_obs = list(true_dist.rvs(1))\n",
    "    obs += new_obs\n",
    "    \n",
    "# timing\n",
    "end = time.time() - start\n",
    "print(end)\n",
    "\n",
    "# let us plot the results #\n",
    "\n",
    "# plotting and filling\n",
    "ax.plot(x_grid, dens_list[0], label='Density of the posterior', alpha=0.5)\n",
    "ax.fill_between(x_grid, dens_list[0], alpha=0.5)\n",
    "\n",
    "# plotting the observations\n",
    "ax.hist(obs_list[0], bins=np.linspace(-2.0,2.0,50), label='Observations', density=True);\n",
    "\n",
    "# plotting the true mean\n",
    "ax.plot([TRUE_MU, TRUE_MU], [0, np.max(np.array(dens_list))], 'k--', label='True mean')\n",
    "\n",
    "# legend and titles\n",
    "ax.legend()\n",
    "ax.set_title('Exact bayesian inference over the mean of a Gaussian distribution')\n",
    "ax.set_xlabel('$x$'); ax.set_ylabel('Density'); plt.tight_layout()\n",
    "ax.set_ylim(0, np.max(np.array(dens_list)))\n",
    "\n",
    "# function for updating\n",
    "def animate(i):\n",
    "    \n",
    "    # plotting and filling\n",
    "    ax.clear()\n",
    "    ax.plot(x_grid, dens_list[i], label='Density of the posterior', alpha=0.5)\n",
    "    ax.fill_between(x_grid, dens_list[i], alpha=0.5)\n",
    "\n",
    "    # plotting the observations\n",
    "    ax.hist(obs_list[i], bins=np.linspace(-2.0,2.0,50), label='Observations', density=True);\n",
    "\n",
    "    # plotting the true mean\n",
    "    ax.plot([TRUE_MU, TRUE_MU], [0, np.max(np.array(dens_list))], 'k--', label='True mean')\n",
    "\n",
    "    # legend and titles\n",
    "    ax.legend()\n",
    "    ax.set_title('Exact bayesian inference over the mean of a Gaussian distribution')\n",
    "    ax.set_xlabel('$x$'); ax.set_ylabel('Density'); plt.tight_layout()    \n",
    "    ax.set_ylim(0, np.max(np.array(dens_list)))\n",
    "\n",
    "    return ()\n",
    "\n",
    "# function for creating animation\n",
    "anim = FuncAnimation(fig, animate, frames=N_ROUNDS, interval=250, blit=True)\n",
    "\n",
    "# showing\n",
    "video = HTML(anim.to_html5_video())\n",
    "\n",
    "# closing figures and then showing video\n",
    "plt.close();\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The animation shows the exact posterior distribution (blue) given incremental data (red). We can see that exact inference is working as we would expect: the posterior distribution concentrates with more data, also getting closer to the true mean. The prior can act as a form of regularization here: if the prior is more concentrated, it is harder to move away from it. I invite you to try the code out to check that. The algorithm is very efficient: 100 calculations took 0.10 seconds.\n",
    "\n",
    "Even if we actually can calculate the posterior analytically in this case, most of the times it will not be possible, as we discussed previously. That's where approximate inference comes into play. Let us apply it to the same problem and compare the results to exact inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC Sampling\n",
    "\n",
    "Let us now imagine that calculating the model evidence $P(x_k)$ is intractable and we cannot solve our inference problem analytically. In this case, we have to use approximate inference techniques. The first we're going to try is Markov chain Monte Carlo sampling. This class of algorithms helps us to approximate posterior distributions by (roughly) making a random walk process gravitate around the maximum of the product of likelihood and prior density functions. Specifically, let us try to use the [Metropolis-Hastings algorithm](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm). I will first show how to implement it from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings from scratch\n",
    "\n",
    "It's not very hard to implement the algorithm from scratch. For a more detailed tutorial, follow [this excellent post](http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/) which helped me a lot to understand what is going on under the hood. \n",
    "\n",
    "Remember that we want to estimate the probability distribution of the mean $\\mu_k$ for each bandit $k$ given some observations $x_k$. We can use Bayes formula do estimate that:\n",
    "\n",
    "$$\\large P(\\mu_k\\ |\\ x_k) = \\frac{P(x_k\\ |\\ \\mu_k) \\cdot{} P(\\mu_k)}{P(x_k)}$$\n",
    "\n",
    "Calculating the product between the likelihood and prior $P(x_k\\ |\\ \\mu_k) \\cdot{} P(\\mu_k)$ is easy. The problem lies in calculating the evidence $P(x_k)$, as it may become a very difficult integral (even if in our case is still tractable):\n",
    "\n",
    "$$\\large P(x_k) = \\int_\\mu P(x_k\\ |\\ \\mu_k) \\, \\mathrm{d}\\mu_k$$\n",
    "\n",
    "The Metropolis-Hastings algorithm bypasses this problem by only needing the prior and likelihood product. It starts by choosing a initial sampling point $\\mu^t$ and defining a proposal distribution, which is generally a normal centered at zero $\\mathcal{N}(0, \\sigma_p^2)$. Then, it progresses as following:\n",
    "\n",
    "1. Initialize a list of samples `mu_list` with a single point $\\mu^t$ and proposal distribution $\\mathcal{N}(0, \\sigma_p^2)$\n",
    "2. Propose a new sample $\\mu^{t+1}$ using the proposal distribution $\\mu^{t+1} = \\mu^t + \\mathcal{N}(0, \\sigma_p^2)$\n",
    "3. Calculate the prior and likelihood product for the current sample $f(\\mu^t) = P(x_k\\ |\\ \\mu^t) \\cdot{} P(\\mu^t)$ and proposed sample $f(\\mu^{t+1}) = P(x_k\\ |\\ \\mu^{t+1}) \\cdot{} P(\\mu^{t+1})$\n",
    "4. Calculate the acceptance ratio $\\alpha = f(\\mu^{t+1})/f(\\mu^t)$\n",
    "5. With probability $\\alpha$, accept the proposed sample and add it to the list of samples `mu_list`. If not accepted, add the current sample to `mu_list`, as we will propose a new sample from it again\n",
    "8. Go back to (2) until a satisfactory number of samples is collected\n",
    "\n",
    "It was proved that by accepting samples according to the acceptance ratio $\\alpha$ our `mu_list` will contain samples that approximate the true posterior distribution. Thus, if we sample for long enough, we will have a reasonable approximation. The magic is that \n",
    "$$\\large \\alpha = \\frac{P(x_k | \\mu^{t+1}) \\cdot{} P(\\mu_k)}{P(x_k | \\mu^t) \\cdot{} P(\\mu_k)} = \\frac{\\frac{P(x_k | \\mu^{t+1}) \\cdot{} P(\\mu_k)}{P(x_k)}}{\\frac{P(x_k | \\mu^t) \\cdot{} P(\\mu_k)}{P(x_k)}}$$\n",
    "\n",
    "such that the likelihood and prior product is sufficient to be proportional to the true posterior for us to get samples from it. We can easily implement this algorithm in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for exact gaussian inference\n",
    "class MetropolisHastingsGaussianInference:\n",
    "    \n",
    "    # initializing with prior paramters\n",
    "    def __init__(self, prior_mu, prior_sigma, likelihood_sigma, proposal_width):\n",
    "        \n",
    "        # storing\n",
    "        self.prior_mu = prior_mu\n",
    "        self.prior_sigma = prior_sigma\n",
    "        self.likelihood_sigma = likelihood_sigma\n",
    "        self.proposal_width = proposal_width\n",
    "                \n",
    "    # fitting the posterior for the mean\n",
    "    def get_posterior(self, obs, n_samples, burnin, thin):\n",
    "        \n",
    "        # checking if there is any observation before proceeding\n",
    "        if len(obs) > 0:\n",
    "        \n",
    "            # our prior distribution and pdf for the observations\n",
    "            prior_dist = norm_dist(self.prior_mu, self.prior_sigma)\n",
    "            \n",
    "            # our proposal distribution\n",
    "            proposal_dist = norm_dist(0.0, self.proposal_width)\n",
    "            \n",
    "            # our list of samples\n",
    "            mu_list = []\n",
    "            \n",
    "            # our initial guess, it will be the mean of the prior\n",
    "            current_sample = self.prior_mu\n",
    "            \n",
    "            # loop for our number of desired samples\n",
    "            for i in range(n_samples):\n",
    "                \n",
    "                # adding to the list of samples\n",
    "                mu_list.append(current_sample)\n",
    "                \n",
    "                # our likelihood distribution for the current sample\n",
    "                likelihood_dist_current = norm_dist(current_sample, self.likelihood_sigma)\n",
    "                likelihood_pdf_current = likelihood_dist_current.logpdf(obs).sum()\n",
    "                \n",
    "                # our prior result for current sample\n",
    "                prior_pdf_current =  prior_dist.logpdf(current_sample).sum()\n",
    "                \n",
    "                # the likelihood and prior product for current sample\n",
    "                product_current = likelihood_pdf_current + prior_pdf_current\n",
    "                \n",
    "                # getting the proposed sample\n",
    "                proposed_sample = current_sample + proposal_dist.rvs(1)[0]\n",
    "            \n",
    "                # our likelihood distribution for the proposed sample\n",
    "                likelihood_dist_proposed = norm_dist(proposed_sample, self.likelihood_sigma)\n",
    "                likelihood_pdf_proposed = likelihood_dist_proposed.logpdf(obs).sum()\n",
    "                \n",
    "                # our prior result for proposed sample\n",
    "                prior_pdf_proposed =  prior_dist.logpdf(proposed_sample).sum()                \n",
    "                \n",
    "                # the likelihood and prior product for proposed sample\n",
    "                product_proposed = likelihood_pdf_proposed + prior_pdf_proposed\n",
    "                \n",
    "                # acceptance rate\n",
    "                acceptance_rate = np.exp(product_proposed - product_current)\n",
    "                \n",
    "                # deciding if we accept proposed sample: if accepted, update current\n",
    "                if np.random.uniform() < acceptance_rate:\n",
    "                    current_sample = proposed_sample\n",
    "                    \n",
    "            # return posterior density via samples\n",
    "            return np.array(mu_list)[burnin::thin]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # return samples from the prior\n",
    "            return norm_dist(self.prior_mu, self.prior_sigma).rvs(int((n_samples - burnin)/thin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the algorithm working like we did in the exact inference case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true paramters\n",
    "TRUE_MU = 0.2\n",
    "TRUE_SIGMA = 1.0\n",
    "N_ROUNDS = 100\n",
    "\n",
    "# instatating our exact inference object \n",
    "# and defining prior hyperparameters:\n",
    "infer = MetropolisHastingsGaussianInference(0.0, 1.0, TRUE_SIGMA, 0.25)\n",
    "exact_infer = ExactGaussianInference(0.0, 1.0, TRUE_SIGMA)\n",
    "\n",
    "# true distribution\n",
    "true_dist = norm_dist(TRUE_MU, TRUE_SIGMA)\n",
    "\n",
    "# opening figure \n",
    "fig, ax = plt.subplots(figsize=(10, 5), dpi=150)\n",
    "\n",
    "# our grid values\n",
    "x_grid = np.linspace(-2.0, 2.0, 2000)\n",
    "\n",
    "# lists for accumulating round results\n",
    "exact_dens_list = []\n",
    "dens_list = []\n",
    "obs_list = []\n",
    "\n",
    "# list of observations which will grow through the rounds\n",
    "obs = []\n",
    "\n",
    "# timing\n",
    "start = time.time()\n",
    "\n",
    "# loop for each round\n",
    "for round in range(N_ROUNDS):\n",
    "    \n",
    "    ## calculating approximate posterior ##\n",
    "    \n",
    "    # updating the object with the data and getting posterior\n",
    "    dens = infer.get_posterior(obs, 1000, 500, 2)\n",
    "    \n",
    "    # saving results in lists\n",
    "    dens_list.append(dens)\n",
    "    obs_list += [np.array(obs)]\n",
    "    \n",
    "    ## calculating exact posterior ##\n",
    "    \n",
    "    # updating the object with the data and getting posterior\n",
    "    exact_posterior = exact_infer.get_posterior(obs)\n",
    "    \n",
    "    # generating density for the posterior\n",
    "    exact_dens = exact_posterior.pdf(x_grid)\n",
    "    \n",
    "    # saving results in lists\n",
    "    exact_dens_list.append(exact_dens)\n",
    "    \n",
    "    # generating some data\n",
    "    new_obs = list(true_dist.rvs(1))\n",
    "    obs += new_obs\n",
    "    \n",
    "# timing\n",
    "end = time.time() - start\n",
    "print(end)\n",
    "    \n",
    "# let us plot the results #\n",
    "\n",
    "# plotting and filling, exact\n",
    "ax.plot(x_grid, exact_dens_list[0], label='Analytical posterior', alpha=0.5)\n",
    "ax.fill_between(x_grid, exact_dens_list[0], alpha=0.5)\n",
    "\n",
    "# plotting the observations\n",
    "ax.hist(obs_list[0], bins=np.linspace(-2.0,2.0,50), label='Observations', density=True);\n",
    "\n",
    "# plotting and filling\n",
    "ax.hist(dens_list[0], label='Samples from approximate posterior', alpha=0.5, bins=np.linspace(-2.0,2.0,200), density=True)\n",
    "\n",
    "# plotting the true mean\n",
    "ax.plot([TRUE_MU, TRUE_MU], [0, 100], 'k--', label='True mean')\n",
    "\n",
    "# legend and titles\n",
    "ax.legend()\n",
    "ax.set_title('Metropolis-Hastings from scratch: $\\mu$ posterior samples')\n",
    "ax.set_xlabel('$x$'); ax.set_ylabel('Density'); #plt.tight_layout()\n",
    "ax.set_ylim(0, np.max(np.array(exact_dens_list)))\n",
    "\n",
    "# function for updating\n",
    "def animate(i):\n",
    "    \n",
    "    # plotting and filling\n",
    "    ax.clear()\n",
    "    ax.plot(x_grid, exact_dens_list[i], label='Analytical posterior', alpha=0.5)\n",
    "    ax.fill_between(x_grid, exact_dens_list[i], alpha=0.5)\n",
    "\n",
    "    # plotting the observations\n",
    "    ax.hist(obs_list[i], bins=np.linspace(-2.0,2.0,50), label='Observations', density=True);\n",
    "\n",
    "    # plotting approximate posterior\n",
    "    ax.hist(dens_list[i], label='Samples from approximate posterior', alpha=0.5, bins=np.linspace(-2.0,2.0,200), density=True)\n",
    "\n",
    "    # plotting the true mean\n",
    "    ax.plot([TRUE_MU, TRUE_MU], [0, 100], 'k--', label='True mean')\n",
    "\n",
    "    # legend and titles\n",
    "    ax.legend()\n",
    "    ax.set_title('Metropolis-Hastings from scratch: $\\mu$ posterior samples')\n",
    "    ax.set_xlabel('$x$'); ax.set_ylabel('Density'); #plt.tight_layout()    \n",
    "    ax.set_ylim(0, np.max(np.array(exact_dens_list)))\n",
    "\n",
    "    return ()\n",
    "\n",
    "# function for creating animation\n",
    "anim = FuncAnimation(fig, animate, frames=N_ROUNDS, interval=250, blit=True)\n",
    "\n",
    "# showing\n",
    "video = HTML(anim.to_html5_video())\n",
    "\n",
    "# closing figures and then showing video\n",
    "plt.close();\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot, we compare the exact posterior (blue), to the Metropolis-Hastings empirical approximation (purple). It works well, being very close to the exact posterior. But it is very slow, taking 185 seconds to calculate the posteriors to all of the 100 draws. In order to improve that, let us try a better implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings with `edward`\n",
    "\n",
    "Let us now use [`edward`](http://edwardlib.org/), a fairly recent Python library which connects tensorflow with probabilistic models. It supports the Metropolis-Hastings algorithm, which we will implement below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for exact gaussian inference\n",
    "class EdMetropolisHastingsGaussianInference:\n",
    "    \n",
    "    # initializing with prior paramters\n",
    "    def __init__(self, prior_mu, prior_sigma, likelihood_sigma, proposal_width):\n",
    "        \n",
    "        # storing\n",
    "        self.prior_mu = prior_mu\n",
    "        self.prior_sigma = prior_sigma\n",
    "        self.likelihood_sigma = likelihood_sigma\n",
    "        self.proposal_width = proposal_width\n",
    "                \n",
    "    # fitting the posterior for the mean\n",
    "    def get_posterior(self, obs, n_samples, burnin, thin):\n",
    "        \n",
    "        # checking if there is any observation before proceeding\n",
    "        if len(obs) > 0:\n",
    "        \n",
    "            # making the computation graph variables self-contained and reusable\n",
    "            with tf.variable_scope('mcmc_model', reuse=tf.AUTO_REUSE) as scope:\n",
    "\n",
    "                # prior definition as tensorflow variables\n",
    "                prior_mu = tf.Variable(self.prior_mu, dtype=tf.float32, trainable=False)\n",
    "                prior_sigma = tf.Variable(self.prior_sigma, dtype=tf.float32, trainable=False)\n",
    "\n",
    "                # prior distribution\n",
    "                mu_prior = Normal(prior_mu, prior_sigma)\n",
    "\n",
    "                # likelihood\n",
    "                mu_likelihood = Normal(mu_prior, self.likelihood_sigma, sample_shape=len(obs))\n",
    "\n",
    "                # posterior distribution\n",
    "                mu_posterior = Empirical(tf.Variable(tf.zeros(n_samples)))\n",
    "\n",
    "                # proposal distribution\n",
    "                mu_proposal = Normal(loc=mu_prior, scale=self.proposal_width)\n",
    "            \n",
    "            # making session self-contained\n",
    "            with tf.Session() as sess:\n",
    "            \n",
    "                # inference object\n",
    "                inference = MetropolisHastings({mu_prior: mu_posterior}, {mu_prior: mu_proposal}, data={mu_likelihood: obs})\n",
    "                inference.run(n_print=0)\n",
    "\n",
    "                # getting session and extracting samples\n",
    "                mu_list = sess.run(mu_posterior.get_variables())[0]\n",
    "\n",
    "            # return posterior density via samples\n",
    "            return np.array(mu_list)[burnin::thin]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # return samples from the prior\n",
    "            return norm_dist(self.prior_mu, self.prior_sigma).rvs(int((n_samples - burnin)/thin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to the video, so we can compare to the implementation I built from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# true paramters\n",
    "TRUE_MU = 0.2\n",
    "TRUE_SIGMA = 1.0\n",
    "N_ROUNDS = 100\n",
    "\n",
    "# instatating our exact inference object \n",
    "# and defining prior hyperparameters:\n",
    "infer = EdMetropolisHastingsGaussianInference(0.0, 1.0, TRUE_SIGMA, 0.25)\n",
    "exact_infer = ExactGaussianInference(0.0, 1.0, TRUE_SIGMA)\n",
    "\n",
    "# true distribution\n",
    "true_dist = norm_dist(TRUE_MU, TRUE_SIGMA)\n",
    "\n",
    "# opening figure \n",
    "fig, ax = plt.subplots(figsize=(10, 5), dpi=150)\n",
    "\n",
    "# our grid values\n",
    "x_grid = np.linspace(-2.0, 2.0, 2000)\n",
    "\n",
    "# lists for accumulating round results\n",
    "exact_dens_list = []\n",
    "dens_list = []\n",
    "obs_list = []\n",
    "\n",
    "# list of observations which will grow through the rounds\n",
    "obs = []\n",
    "\n",
    "# timing\n",
    "start = time.time()\n",
    "\n",
    "# loop for each round\n",
    "for round in range(N_ROUNDS):\n",
    "    \n",
    "    ## calculating approximate posterior ##\n",
    "    \n",
    "    # updating the object with the data and getting posterior\n",
    "    dens = infer.get_posterior(obs, 1000, 500, 2)\n",
    "    \n",
    "    # saving results in lists\n",
    "    dens_list.append(dens)\n",
    "    obs_list += [np.array(obs)]\n",
    "    \n",
    "    ## calculating exact posterior ##\n",
    "    \n",
    "    # updating the object with the data and getting posterior\n",
    "    exact_posterior = exact_infer.get_posterior(obs)\n",
    "    \n",
    "    # generating density for the posterior\n",
    "    exact_dens = exact_posterior.pdf(x_grid)\n",
    "    \n",
    "    # saving results in lists\n",
    "    exact_dens_list.append(exact_dens)\n",
    "    \n",
    "    # generating some data\n",
    "    new_obs = list(true_dist.rvs(1))\n",
    "    obs += new_obs\n",
    "    \n",
    "# timing\n",
    "end = time.time() - start\n",
    "print(end)\n",
    "    \n",
    "# let us plot the results #\n",
    "\n",
    "# plotting and filling, exact\n",
    "ax.plot(x_grid, exact_dens_list[0], label='Analytical posterior', alpha=0.5)\n",
    "ax.fill_between(x_grid, exact_dens_list[0], alpha=0.5)\n",
    "\n",
    "# plotting the observations\n",
    "ax.hist(obs_list[0], bins=np.linspace(-2.0,2.0,50), label='Observations', density=True);\n",
    "\n",
    "# plotting and filling\n",
    "ax.hist(dens_list[0], label='Samples from approximate posterior', alpha=0.5, bins=np.linspace(-2.0,2.0,200), density=True)\n",
    "\n",
    "# plotting the true mean\n",
    "ax.plot([TRUE_MU, TRUE_MU], [0, 100], 'k--', label='True mean')\n",
    "\n",
    "# legend and titles\n",
    "ax.legend()\n",
    "ax.set_title('Metropolis-Hastings with edward: $\\mu$ posterior samples')\n",
    "ax.set_xlabel('$x$'); ax.set_ylabel('Density'); #plt.tight_layout()\n",
    "ax.set_ylim(0, np.max(np.array(exact_dens_list)))\n",
    "\n",
    "# function for updating\n",
    "def animate(i):\n",
    "    \n",
    "    # plotting and filling\n",
    "    ax.clear()\n",
    "    ax.plot(x_grid, exact_dens_list[i], label='Analytical posterior', alpha=0.5)\n",
    "    ax.fill_between(x_grid, exact_dens_list[i], alpha=0.5)\n",
    "\n",
    "    # plotting the observations\n",
    "    ax.hist(obs_list[i], bins=np.linspace(-2.0,2.0,50), label='Observations', density=True);\n",
    "\n",
    "    # plotting approximate posterior\n",
    "    ax.hist(dens_list[i], label='Samples from approximate posterior', alpha=0.5, bins=np.linspace(-2.0,2.0,200), density=True)\n",
    "\n",
    "    # plotting the true mean\n",
    "    ax.plot([TRUE_MU, TRUE_MU], [0, 100], 'k--', label='True mean')\n",
    "\n",
    "    # legend and titles\n",
    "    ax.legend()\n",
    "    ax.set_title('Metropolis-Hastings with edward: $\\mu$ posterior samples')\n",
    "    ax.set_xlabel('$x$'); ax.set_ylabel('Density'); #plt.tight_layout()    \n",
    "    ax.set_ylim(0, np.max(np.array(exact_dens_list)))\n",
    "\n",
    "    return ()\n",
    "\n",
    "# function for creating animation\n",
    "anim = FuncAnimation(fig, animate, frames=N_ROUNDS, interval=250, blit=True)\n",
    "\n",
    "# showing\n",
    "video = HTML(anim.to_html5_video())\n",
    "\n",
    "# closing figures and then showing video\n",
    "plt.close();\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, `edward` was slower than my implementation. Maybe I made a mistake in the code or building the computational graph in `tensorflow` takes a long time compared to actually sampling. Nevertheless, the posterior looks good as well.\n",
    "\n",
    "Despite good results, MCMC Sampling is still very slow for our application. There is another class of algorithms that try improve that by avoiding expensive sampling and casting posterior inference as an optimization problem. Let us explore them next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Inference\n",
    "\n",
    "**Variational Inference** is the name of the class of inference algorithms that avoid sampling and cast posterior inference as an optimization problem. The main idea is to use a distribution from a known family $q(z\\ ;\\ \\lambda)$ to approximate the true posterior $p(z\\ |\\ x)$ by optimizing $\\lambda$ to match it. The distribution $q(z\\ ;\\ \\lambda)$ is called the **variational posterior**.\n",
    "\n",
    "One way to measure how closely $q$ matches $p$ is the Kullback-Leibler divergence:\n",
    "\n",
    "$$\\large KL(q\\ ||\\ p) = \\sum_x q(z\\ ;\\ \\lambda)\\ \\textrm{log}\\ \\frac{q(z\\ ;\\ \\lambda)}{p(z\\ |\\ x)}$$\n",
    "\n",
    "But $p(z\\ |\\ x)$ is still intractable, as it includes the normalization constant $p(x)$:\n",
    "\n",
    "$$\\large p(z\\ |\\ x) = \\frac{p(x\\ |\\ z)\\ p(z)}{p(x)}$$\n",
    "\n",
    "However, we can replace $p(z\\ |\\ x)$ by its tractable unnormalized counterpart $\\tilde{p}(z\\ |\\ x) = p(z\\ |\\ x)\\ p(x)$ (as in [(Murphy, 2012)](https://amstat.tandfonline.com/doi/abs/10.1080/09332480.2014.914768?journalCode=ucha20#.WyyqpadKiUk)):\n",
    "\n",
    "$$\\large KL(q\\ ||\\ \\tilde{p}) = \\sum_x q(z\\ ;\\ \\lambda)\\ \\textrm{log}\\ \\frac{q(z\\ ;\\ \\lambda)}{\\tilde{p}(z\\ |\\ x)} = \\sum_x q(z\\ ;\\ \\lambda)\\ \\textrm{log}\\ \\frac{q(z\\ ;\\ \\lambda)}{p(z\\ |\\ x)} -\\ \\textrm{log}\\ p(x) = KL(q\\ ||\\ p) -\\ \\textrm{log}\\ p(x)$$\n",
    "\n",
    "Thus, minimizing $KL(q || \\tilde{p})$ is the same as minimizing $KL(q\\ ||\\ p)$ with respect to the variational parameters $\\lambda$, as they have no effect on the normalization constant $\\textrm{log}\\ p(x)$. Then, our cost function becomes\n",
    "\n",
    "$$\\large J(\\lambda) = KL(q\\ ||\\ \\tilde{p}) = KL(q\\ ||\\ p) -\\ \\textrm{log}\\ p(x)$$\n",
    "\n",
    "which can be minimized to find optimal variational parameters $\\lambda$. In general, we actually maximize $L(\\lambda) = - J(\\lambda) = - KL(q\\ ||\\ p) +\\ \\textrm{log}\\ p(x)$, the so-called **evidence lower bound (ELBO)**, as $- KL(q\\ ||\\ p) +\\ \\textrm{log}\\ p(x) \\leq\\ \\textrm{log}\\ p(x)$. There is a simpler way to write the ELBO:\n",
    "\n",
    "$$\\large \\textrm{ELBO}(\\lambda) =  \\mathbb{E}_q[\\tilde{p}(z\\ |\\ x)] - \\mathbb{E}_q[log\\ q(\\lambda)]$$\n",
    "\n",
    "$\\mathbb{E}_q[\\tilde{p}(z\\ |\\ x)]$ measures goodness-of-fit of the model and encourages $q(\\lambda)$ to focus probability mass where the model puts high probability. On the other hand, the entropy of $q(\\lambda)$, $- \\mathbb{E}_q[log\\ q(\\lambda)]$ encourages $q(\\lambda)$ to spread probability mass, avoiding the concentration incentivized by the first term.\n",
    "\n",
    "In our case of modeling expected rewards, we can replace $q(\\lambda) = \\mathcal{N}(\\mu_{var}, \\sigma_{var})$ where $\\mu_{var}$ and $\\sigma_{var}$ are the variational parameters to be optimized and $\\tilde{p}(z\\ |\\ x) = P(x_k\\ |\\ \\mu_k) \\cdot{} P(\\mu_k)$, the likelihood and prior product we used to implement the Metropolis-Hastings algorithm. To get the expectations we take some samples of the variational posterior at each iteration in the optimization. I'll show next how to implement this from scratch and also using `edward`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From scratch\n",
    "\n",
    "Let us first try to implement Variational Inference from scratch. As suggested by [these guys](https://www.cs.toronto.edu/~duvenaud/papers/blackbox.pdf), we can use the `autograd` module to automatically compute the gradient for the ELBO, which greatly simplifies the implementation. We start by defining the ELBO, our cost function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining ELBO using functional programming (inspired by adagrad example)\n",
    "def black_box_variational_inference(unnormalized_posterior, num_samples):\n",
    "    \n",
    "    # method to just unpack paramters from paramter vector \n",
    "    def unpack_params(params):\n",
    "        mu, log_sigma = params[0], params[1]\n",
    "        return mu, agnp.exp(log_sigma)\n",
    "    \n",
    "    # function to compute entropy of a gaussian\n",
    "    def gaussian_entropy(sigma):\n",
    "        return agnp.log(sigma*agnp.sqrt(2*agnp.pi*agnp.e))\n",
    "    \n",
    "    # method where the actual objective is calculated\n",
    "    def elbo_target(params, t):\n",
    "        \n",
    "        # unpacking parameters\n",
    "        mu, sigma = unpack_params(params)\n",
    "        \n",
    "        # taking samples of the variational distribution\n",
    "        samples = agnpr.randn(num_samples) * sigma + mu\n",
    "        \n",
    "        # calculating the ELBO using the samples, entropy, and unnormalized_posterior\n",
    "        lower_bound = agnp.mean(gaussian_entropy(sigma) + unnormalized_posterior(samples, t))\n",
    "                \n",
    "        # returning minus ELBO because the optimizaztion algorithms are set to minimize\n",
    "        return -lower_bound\n",
    "    \n",
    "    # computing gradient via autograd\n",
    "    gradient = grad(elbo_target)\n",
    "    \n",
    "    # returning all the stuff\n",
    "    return elbo_target, gradient, unpack_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool. Now we define a function that implements the unnormalized posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to implement unnormalized posterior\n",
    "def get_unnormalized_posterior(obs, prior_mu, prior_std, likelihood_std):\n",
    "    \n",
    "    # function that we will return\n",
    "    def unnorm_posterior(samples, t):\n",
    "                \n",
    "        # calculating prior density\n",
    "        prior_density = agnorm.logpdf(samples, loc=prior_mu, scale=prior_std)\n",
    "        \n",
    "        # calculating likelihood density\n",
    "        likelihood_density = agnp.sum(agnorm.logpdf(samples.reshape(-1,1), loc=obs, scale=likelihood_std), axis=1)\n",
    "        \n",
    "        # return product\n",
    "        return prior_density + likelihood_density\n",
    "    \n",
    "    # returning the function\n",
    "    return unnorm_posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we implement an inference class so we can manipulate the variational posterior and show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for exact gaussian inference\n",
    "class VariationalGaussianInference:\n",
    "    \n",
    "    # initializing with prior paramters\n",
    "    def __init__(self, prior_mu, prior_sigma, likelihood_sigma, gradient_samples=8):\n",
    "        \n",
    "        # storing\n",
    "        self.prior_mu = prior_mu\n",
    "        self.prior_sigma = prior_sigma\n",
    "        self.post_mu = prior_mu\n",
    "        self.post_sigma = prior_sigma\n",
    "        self.likelihood_sigma = likelihood_sigma\n",
    "        self.gradient_samples = gradient_samples\n",
    "                \n",
    "    # fitting the posterior for the mean\n",
    "    def get_posterior(self, obs):\n",
    "        \n",
    "        # getting unnormalized posterior\n",
    "        unnorm_posterior = get_unnormalized_posterior(obs, self.prior_mu, self.prior_sigma, self.likelihood_sigma)\n",
    "\n",
    "        # getting our functionals for the optimization problem\n",
    "        variational_objective, gradient, unpack_params = \\\n",
    "        black_box_variational_inference(unnorm_posterior, self.gradient_samples)\n",
    "\n",
    "        # iniitializing parameters\n",
    "        init_var_params = agnp.array([self.prior_mu, np.log(self.prior_sigma)])\n",
    "\n",
    "        # optimzing\n",
    "        variational_params = adam(gradient, init_var_params, step_size=0.1, num_iters=200)\n",
    "\n",
    "        # updating posterior parameters\n",
    "        self.post_mu, self.post_sigma = variational_params[0], np.exp(variational_params[1])\n",
    "            \n",
    "        # return posterior\n",
    "        return norm_dist(self.post_mu, self.post_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now see how our approximation fares against exact inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true paramters\n",
    "TRUE_MU = 0.2\n",
    "TRUE_SIGMA = 1.0\n",
    "N_ROUNDS = 100\n",
    "\n",
    "# instatating our exact inference object \n",
    "# and defining prior hyperparameters:\n",
    "infer = VariationalGaussianInference(0.0, 1.0, TRUE_SIGMA, gradient_samples=16)\n",
    "exact_infer = ExactGaussianInference(0.0, 1.0, TRUE_SIGMA)\n",
    "\n",
    "# true distribution\n",
    "true_dist = norm_dist(TRUE_MU, TRUE_SIGMA)\n",
    "\n",
    "# opening figure \n",
    "fig, ax = plt.subplots(figsize=(10, 5), dpi=150)\n",
    "\n",
    "# our grid values\n",
    "x_grid = np.linspace(-2.0, 2.0, 2000)\n",
    "\n",
    "# lists for accumulating round results\n",
    "exact_dens_list = []\n",
    "dens_list = []\n",
    "obs_list = []\n",
    "\n",
    "# list of observations which will grow through the rounds\n",
    "obs = []\n",
    "\n",
    "# timing\n",
    "start = time.time()\n",
    "\n",
    "# loop for each round\n",
    "for round in range(N_ROUNDS):\n",
    "    \n",
    "    ## calculating approximate posterior ##\n",
    "    \n",
    "    # updating the object with the data and getting posterior\n",
    "    posterior = infer.get_posterior(obs)\n",
    "    \n",
    "    # generating density for the posterior\n",
    "    dens = posterior.pdf(x_grid)\n",
    "    \n",
    "    # saving results in lists\n",
    "    dens_list.append(dens)\n",
    "    obs_list += [np.array(obs)]\n",
    "    \n",
    "    ## calculating exact posterior ##\n",
    "    \n",
    "    # updating the object with the data and getting posterior\n",
    "    exact_posterior = exact_infer.get_posterior(obs)\n",
    "    \n",
    "    # generating density for the posterior\n",
    "    exact_dens = exact_posterior.pdf(x_grid)\n",
    "    \n",
    "    # saving results in lists\n",
    "    exact_dens_list.append(exact_dens)\n",
    "    \n",
    "    # generating some data\n",
    "    new_obs = list(true_dist.rvs(1))\n",
    "    obs += new_obs\n",
    "    \n",
    "# timing\n",
    "end = time.time() - start\n",
    "print(end)    \n",
    "    \n",
    "# let us plot the results #\n",
    "\n",
    "# plotting and filling, exact\n",
    "ax.plot(x_grid, exact_dens_list[0], label='Analytical posterior', alpha=0.5)\n",
    "ax.fill_between(x_grid, exact_dens_list[0], alpha=0.5)\n",
    "\n",
    "# plotting the observations\n",
    "ax.hist(obs_list[0], bins=np.linspace(-2.0,2.0,50), label='Observations', density=True);\n",
    "\n",
    "# plotting and filling\n",
    "ax.plot(x_grid, dens_list[0], label='Variational posterior', alpha=0.5)\n",
    "ax.fill_between(x_grid, dens_list[0], alpha=0.5, color='C2')\n",
    "\n",
    "# plotting the true mean\n",
    "ax.plot([TRUE_MU, TRUE_MU], [0, 100], 'k--', label='True mean')\n",
    "\n",
    "# legend and titles\n",
    "ax.legend()\n",
    "ax.set_title('Variational inference from scratch: comparing $q(z\\ ;\\ \\lambda)$ and $p(z\\ |\\ x)$')\n",
    "ax.set_xlabel('$x$'); ax.set_ylabel('Density'); #plt.tight_layout()\n",
    "ax.set_ylim(0, np.max(np.array(exact_dens_list)))\n",
    "\n",
    "# function for updating\n",
    "def animate(i):\n",
    "    \n",
    "    # plotting and filling\n",
    "    ax.clear()\n",
    "    ax.plot(x_grid, exact_dens_list[i], label='Analytical posterior', alpha=0.5)\n",
    "    ax.fill_between(x_grid, exact_dens_list[i], alpha=0.5)\n",
    "    \n",
    "    # plotting the observations\n",
    "    ax.hist(obs_list[i], bins=np.linspace(-2.0,2.0,50), label='Observations', density=True);\n",
    "\n",
    "    # plotting variational posterior\n",
    "    ax.plot(x_grid, dens_list[i], label='Variational posterior', alpha=0.5)\n",
    "    ax.fill_between(x_grid, dens_list[i], alpha=0.5, color='C2')\n",
    "\n",
    "    # plotting the true mean\n",
    "    ax.plot([TRUE_MU, TRUE_MU], [0, 100], 'k--', label='True mean')\n",
    "\n",
    "    # legend and titles\n",
    "    ax.legend()\n",
    "    ax.set_title('Variational inference from scratch: comparing $q(z\\ ;\\ \\lambda)$ and $p(z\\ |\\ x)$')\n",
    "    ax.set_xlabel('$x$'); ax.set_ylabel('Density'); #plt.tight_layout()    \n",
    "    ax.set_ylim(0, np.max(np.array(exact_dens_list)))\n",
    "\n",
    "    return ()\n",
    "\n",
    "# function for creating animation\n",
    "anim = FuncAnimation(fig, animate, frames=N_ROUNDS, interval=250, blit=True)\n",
    "\n",
    "# showing\n",
    "video = HTML(anim.to_html5_video())\n",
    "\n",
    "# closing figures and then showing video\n",
    "plt.close();\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very nice. The variational posterior found is very close to the exact posterior. This result shows us that we can nicely estimate the ELBO with just a few samples from $q(z\\ ;\\ \\lambda)$ (16 in this case). The `autograd` package helped a lot in automatically finding the gradient of the ELBO, making it very simple to optimize it. This code is an order of magnitude faster than the code that implements Metropolis-Hastings as well ($\\tilde\\ 19$ seconds). The main downside is that the implementation is more complicated than before. Nevertheless, the result is awesome. Let us try to implement this with `edward` now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With `edward`\n",
    "\n",
    "Let us now try to implement variational inference with `edward`. It provides many forms of VI, the closest to what I used in the previous section being `ReparameterizationEntropyKLqp`, I think. \"Reparametrization\" comes from the line `agnpr.randn(num_samples) * sigma + mu` where I represented a normal distribution $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ as $X \\sim \\sigma^2 \\cdot{} \\mathcal{N}(0, 1) + \\mu$ to simplify gradient calculation. \"Entropy\" comes from using an analytical entropy term, just like in my definition of the ELBO `lower_bound = agnp.mean(gaussian_entropy(sigma) + unnormalized_posterior(samples, t))`. Please do make a comment if you find this innacurate or have a suggestion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for exact gaussian inference\n",
    "class EdVariationalGaussianInference:\n",
    "    \n",
    "    # initializing with prior paramters\n",
    "    def __init__(self, prior_mu, prior_sigma, likelihood_sigma):\n",
    "        \n",
    "        # storing\n",
    "        self.prior_mu = prior_mu\n",
    "        self.prior_sigma = prior_sigma\n",
    "        self.post_mu = prior_mu\n",
    "        self.post_sigma = prior_sigma\n",
    "        self.likelihood_sigma = likelihood_sigma\n",
    "                \n",
    "    # fitting the posterior for the mean\n",
    "    def get_posterior(self, obs):\n",
    "        \n",
    "        # reshaping the observations\n",
    "        obs = np.array(obs).reshape(-1, 1)\n",
    "        \n",
    "        # checking if there is any observation before proceeding\n",
    "        if len(obs) > 0:\n",
    "            \n",
    "            # making the computation graph variables self-contained and reusable\n",
    "            with tf.variable_scope('var_model', reuse=tf.AUTO_REUSE) as scope:\n",
    "\n",
    "                # prior definition as tensorflow variables\n",
    "                prior_mu = tf.Variable([self.prior_mu], dtype=tf.float32, trainable=False)\n",
    "                prior_sigma = tf.Variable([self.prior_sigma], dtype=tf.float32, trainable=False)\n",
    "\n",
    "                # prior distribution\n",
    "                mu_prior = Normal(prior_mu, prior_sigma)\n",
    "\n",
    "                # likelihood\n",
    "                mu_likelihood = Normal(mu_prior, self.likelihood_sigma, sample_shape=obs.shape[0])\n",
    "\n",
    "                # posterior definition as tensorflow variables\n",
    "                post_mu = tf.get_variable(\"post/mu\", [1])\n",
    "                post_sigma = tf.nn.softplus(tf.get_variable(\"post/sigma\", [1]))\n",
    "\n",
    "                # posterior distribution\n",
    "                mu_posterior = Normal(loc=post_mu, scale=post_sigma)\n",
    "            \n",
    "            # making session self-contained\n",
    "            with tf.Session() as sess:\n",
    "\n",
    "                # inference object\n",
    "                inference = ReparameterizationEntropyKLqp({mu_prior: mu_posterior}, data={mu_likelihood: obs})\n",
    "                \n",
    "                # running inference\n",
    "                inference.run(n_print=0)\n",
    "                \n",
    "                # extracting variational parameters\n",
    "                # careful: need to apply inverse softplus to sigma\n",
    "                variational_params = sess.run(mu_posterior.get_variables())\n",
    "                \n",
    "                # storing to attributes\n",
    "                self.post_mu = variational_params[0] \n",
    "                self.post_sigma = np.log(np.exp(variational_params[1]) + 1)\n",
    "                \n",
    "        # return samples from the prior\n",
    "        return norm_dist(self.post_mu, self.post_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edward takes the implementation to a higher level of abstraction, so we need to use less lines of code. Let us run it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# true paramters\n",
    "TRUE_MU = 0.2\n",
    "TRUE_SIGMA = 1.0\n",
    "N_ROUNDS = 100\n",
    "\n",
    "# instatating our exact inference object \n",
    "# and defining prior hyperparameters:\n",
    "infer = EdVariationalGaussianInference(0.0, 1.0, TRUE_SIGMA)\n",
    "exact_infer = ExactGaussianInference(0.0, 1.0, TRUE_SIGMA)\n",
    "\n",
    "# true distribution\n",
    "true_dist = norm_dist(TRUE_MU, TRUE_SIGMA)\n",
    "\n",
    "# opening figure \n",
    "fig, ax = plt.subplots(figsize=(10, 5), dpi=150)\n",
    "\n",
    "# our grid values\n",
    "x_grid = np.linspace(-2.0, 2.0, 2000)\n",
    "\n",
    "# lists for accumulating round results\n",
    "exact_dens_list = []\n",
    "dens_list = []\n",
    "obs_list = []\n",
    "\n",
    "# list of observations which will grow through the rounds\n",
    "obs = []\n",
    "\n",
    "# timing\n",
    "start = time.time()\n",
    "\n",
    "# loop for each round\n",
    "for round in range(N_ROUNDS):\n",
    "    \n",
    "    ## calculating approximate posterior ##\n",
    "    \n",
    "    # updating the object with the data and getting posterior\n",
    "    posterior = infer.get_posterior(obs)\n",
    "    \n",
    "    # generating density for the posterior\n",
    "    dens = posterior.pdf(x_grid)\n",
    "    \n",
    "    # saving results in lists\n",
    "    dens_list.append(dens)\n",
    "    obs_list += [np.array(obs)]\n",
    "    \n",
    "    ## calculating exact posterior ##\n",
    "    \n",
    "    # updating the object with the data and getting posterior\n",
    "    exact_posterior = exact_infer.get_posterior(obs)\n",
    "    \n",
    "    # generating density for the posterior\n",
    "    exact_dens = exact_posterior.pdf(x_grid)\n",
    "    \n",
    "    # saving results in lists\n",
    "    exact_dens_list.append(exact_dens)\n",
    "    \n",
    "    # generating some data\n",
    "    new_obs = list(true_dist.rvs(1))\n",
    "    obs += new_obs\n",
    "    \n",
    "# timing\n",
    "end = time.time() - start\n",
    "print(end)    \n",
    "    \n",
    "# let us plot the results #\n",
    "\n",
    "# plotting and filling, exact\n",
    "ax.plot(x_grid, exact_dens_list[0], label='Analytical posterior', alpha=0.5)\n",
    "ax.fill_between(x_grid, exact_dens_list[0], alpha=0.5)\n",
    "\n",
    "# plotting the observations\n",
    "ax.hist(obs_list[0], bins=np.linspace(-2.0,2.0,50), label='Observations', density=True);\n",
    "\n",
    "# plotting and filling\n",
    "ax.plot(x_grid, dens_list[0], label='Variational posterior', alpha=0.5)\n",
    "ax.fill_between(x_grid, dens_list[0], alpha=0.5, color='C2')\n",
    "\n",
    "# plotting the true mean\n",
    "ax.plot([TRUE_MU, TRUE_MU], [0, 100], 'k--', label='True mean')\n",
    "\n",
    "# legend and titles\n",
    "ax.legend()\n",
    "ax.set_title('Variational inference with edward: comparing $q(z\\ ;\\ \\lambda)$ and $p(z\\ |\\ x)$')\n",
    "ax.set_xlabel('$x$'); ax.set_ylabel('Density'); #plt.tight_layout()\n",
    "ax.set_ylim(0, np.max(np.array(exact_dens_list)))\n",
    "\n",
    "# function for updating\n",
    "def animate(i):\n",
    "    \n",
    "    # plotting and filling\n",
    "    ax.clear()\n",
    "    ax.plot(x_grid, exact_dens_list[i], label='Analytical posterior', alpha=0.5)\n",
    "    ax.fill_between(x_grid, exact_dens_list[i], alpha=0.5)\n",
    "    \n",
    "    # plotting the observations\n",
    "    ax.hist(obs_list[i], bins=np.linspace(-2.0,2.0,50), label='Observations', density=True);\n",
    "\n",
    "    # plotting variational posterior\n",
    "    ax.plot(x_grid, dens_list[i], label='Variational posterior', alpha=0.5)\n",
    "    ax.fill_between(x_grid, dens_list[i], alpha=0.5, color='C2')\n",
    "\n",
    "    # plotting the true mean\n",
    "    ax.plot([TRUE_MU, TRUE_MU], [0, 100], 'k--', label='True mean')\n",
    "\n",
    "    # legend and titles\n",
    "    ax.legend()\n",
    "    ax.set_title('Variational inference with edward: comparing $q(z\\ ;\\ \\lambda)$ and $p(z\\ |\\ x)$')\n",
    "    ax.set_xlabel('$x$'); ax.set_ylabel('Density'); #plt.tight_layout()    \n",
    "    ax.set_ylim(0, np.max(np.array(exact_dens_list)))\n",
    "\n",
    "    return ()\n",
    "\n",
    "# function for creating animation\n",
    "anim = FuncAnimation(fig, animate, frames=N_ROUNDS, interval=250, blit=True)\n",
    "\n",
    "# showing\n",
    "video = HTML(anim.to_html5_video())\n",
    "\n",
    "# closing figures and then showing video\n",
    "plt.close();\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool. The results are good, however the code took much longer to run. This may be due to some tensorflow particularity (my money's on building the computational graph). I'll have a look in the future. Now, to our last contender: **Bootstrapping**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "\n",
    "**Bootstrapping** is the name given to the procedure of iteratively sampling with replacement. Each bootstrap sample approximates a sample from the posterior of our quantity of interest. It is a very cheap and flexible way to estimate posteriors, but it does not come with the flexibility to specify a prior, which could greatly underestimate uncertainty in early rounds of our gaussian bandit game (although there are [proposed ways](https://web.stanford.edu/~bvr/pubs/TS_Tutorial.pdf) to add prior information to it). In order to keep it simple and encourage exploration in the beginning of the game I'll use the following heuristic:\n",
    "\n",
    "1. Specify a mininum number of observations in order to start taking bootstrap samples `min_obs`\n",
    "2. If we have less than `min_obs` observations, the posterior is equal to the prior\n",
    "3. If the number of observations we have is equal to or greater than `min_obs`, we start taking boostrap samples\n",
    "\n",
    "The implementation is the simplest among all algorithms explored in this post:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for exact gaussian inference\n",
    "class BootstrapGaussianInference:\n",
    "    \n",
    "    # initializing with prior paramters\n",
    "    def __init__(self, prior_mu, prior_sigma, min_obs):\n",
    "        \n",
    "        # storing\n",
    "        self.prior_mu = prior_mu\n",
    "        self.prior_sigma = prior_sigma\n",
    "        self.min_obs = min_obs\n",
    "                \n",
    "    # fitting the posterior for the mean\n",
    "    def get_posterior(self, obs, n_samples):\n",
    "        \n",
    "        # reshaping the observations\n",
    "        obs = np.array(obs)\n",
    "        \n",
    "        # checking if there is any observation before proceeding\n",
    "        if len(obs) >= self.min_obs:\n",
    "            \n",
    "            # running many bootstrap samples\n",
    "            btrap_samples = np.array([np.random.choice(obs, len(obs)).mean() for _ in range(n_samples)])\n",
    "            \n",
    "            # return posterior density via samples\n",
    "            return btrap_samples\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # return samples from the prior\n",
    "            return norm_dist(self.prior_mu, self.prior_sigma).rvs(n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how this one handles our inference case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true paramters\n",
    "TRUE_MU = 0.2\n",
    "TRUE_SIGMA = 1.0\n",
    "N_ROUNDS = 100\n",
    "\n",
    "# instatating our exact inference object \n",
    "# and defining prior hyperparameters:\n",
    "infer = BootstrapGaussianInference(0.0, 1.0, 0)\n",
    "exact_infer = ExactGaussianInference(0.0, 1.0, TRUE_SIGMA)\n",
    "\n",
    "# true distribution\n",
    "true_dist = norm_dist(TRUE_MU, TRUE_SIGMA)\n",
    "\n",
    "# opening figure \n",
    "fig, ax = plt.subplots(figsize=(10, 5), dpi=150)\n",
    "\n",
    "# our grid values\n",
    "x_grid = np.linspace(-2.0, 2.0, 2000)\n",
    "\n",
    "# lists for accumulating round results\n",
    "exact_dens_list = []\n",
    "dens_list = []\n",
    "obs_list = []\n",
    "\n",
    "# list of observations which will grow through the rounds\n",
    "obs = []\n",
    "\n",
    "# timing\n",
    "start = time.time()\n",
    "\n",
    "# loop for each round\n",
    "for round in range(N_ROUNDS):\n",
    "    \n",
    "    ## calculating approximate posterior ##\n",
    "    \n",
    "    # updating the object with the data and getting posterior\n",
    "    dens = infer.get_posterior(obs, 1000)\n",
    "    \n",
    "    # saving results in lists\n",
    "    dens_list.append(dens)\n",
    "    obs_list += [np.array(obs)]\n",
    "    \n",
    "    ## calculating exact posterior ##\n",
    "    \n",
    "    # updating the object with the data and getting posterior\n",
    "    exact_posterior = exact_infer.get_posterior(obs)\n",
    "    \n",
    "    # generating density for the posterior\n",
    "    exact_dens = exact_posterior.pdf(x_grid)\n",
    "    \n",
    "    # saving results in lists\n",
    "    exact_dens_list.append(exact_dens)\n",
    "    \n",
    "    # generating some data\n",
    "    new_obs = list(true_dist.rvs(1))\n",
    "    obs += new_obs\n",
    "    \n",
    "# timing\n",
    "end = time.time() - start\n",
    "print(end)\n",
    "    \n",
    "# let us plot the results #\n",
    "\n",
    "# plotting and filling, exact\n",
    "ax.plot(x_grid, exact_dens_list[0], label='Analytical posterior', alpha=0.5)\n",
    "ax.fill_between(x_grid, exact_dens_list[0], alpha=0.5)\n",
    "\n",
    "# plotting the observations\n",
    "ax.hist(obs_list[0], bins=np.linspace(-2.0,2.0,50), label='Observations', density=True);\n",
    "\n",
    "# plotting and filling\n",
    "ax.hist(dens_list[0], label='Samples from approximate posterior', alpha=0.5, bins=np.linspace(-2.0,2.0,200), density=True)\n",
    "\n",
    "# plotting the true mean\n",
    "ax.plot([TRUE_MU, TRUE_MU], [0, 100], 'k--', label='True mean')\n",
    "\n",
    "# legend and titles\n",
    "ax.legend()\n",
    "ax.set_title('Boostrapping: $\\mu$ posterior samples')\n",
    "ax.set_xlabel('$x$'); ax.set_ylabel('Density'); #plt.tight_layout()\n",
    "ax.set_ylim(0, np.max(np.array(exact_dens_list)))\n",
    "\n",
    "# function for updating\n",
    "def animate(i):\n",
    "    \n",
    "    # plotting and filling\n",
    "    ax.clear()\n",
    "    ax.plot(x_grid, exact_dens_list[i], label='Analytical posterior', alpha=0.5)\n",
    "    ax.fill_between(x_grid, exact_dens_list[i], alpha=0.5)\n",
    "\n",
    "    # plotting the observations\n",
    "    ax.hist(obs_list[i], bins=np.linspace(-2.0,2.0,50), label='Observations', density=True);\n",
    "\n",
    "    # plotting approximate posterior\n",
    "    ax.hist(dens_list[i], label='Samples from approximate posterior', alpha=0.5, bins=np.linspace(-2.0,2.0,200), density=True)\n",
    "\n",
    "    # plotting the true mean\n",
    "    ax.plot([TRUE_MU, TRUE_MU], [0, 100], 'k--', label='True mean')\n",
    "\n",
    "    # legend and titles\n",
    "    ax.legend()\n",
    "    ax.set_title('Boostrapping: $\\mu$ posterior samples')\n",
    "    ax.set_xlabel('$x$'); ax.set_ylabel('Density'); #plt.tight_layout()    \n",
    "    ax.set_ylim(0, np.max(np.array(exact_dens_list)))\n",
    "\n",
    "    return ()\n",
    "\n",
    "# function for creating animation\n",
    "anim = FuncAnimation(fig, animate, frames=N_ROUNDS, interval=250, blit=True)\n",
    "\n",
    "# showing\n",
    "video = HTML(anim.to_html5_video())\n",
    "\n",
    "# closing figures and then showing video\n",
    "plt.close();\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set `min_obs` $= 0$ to observe the error in the uncertainty estimate in early periods. In the video, the approximation gets much better after the fifth observation, when it starts closely matching the exact posterior. The whole simulation took approximately 2 seconds, which puts this method as a very strong contender when we prioritize efficiency. Another argument in favor of Bootstrapping is that it can approximate very complex distributions without any model specification. \n",
    "\n",
    "Bootstrapping concludes the set of algorithms I planned to develop in this post. We're now ready to experiment with them on our gaussian bandit problem! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the algorithms to the test\n",
    "\n",
    "Let us now put the inference algorithms we developed face to face for solving the gaussian bandit problem. To reduce computational costs, we will perform the learning step (sampling for MCMC, fitting $q(z\\ ;\\ \\theta)$ for VI) only once every 10 rounds. Let us implement the game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for running one simulation of the gaussian bandit\n",
    "def run_gaussian_bandit(n_rounds, policy):\n",
    "    \n",
    "    # instance of gaussian bandit game\n",
    "    true_sigma = 0.3\n",
    "    gmab = GaussianMAB([0.0,-0.30,-0.15,0.30,0.15], [true_sigma]*5)\n",
    "\n",
    "    # number of bandits\n",
    "    n_bandits = len(gmab.mu)\n",
    "\n",
    "    # lists for ease of use, visualization\n",
    "    k_list = []\n",
    "    reward_list = []\n",
    "    regret_list = []\n",
    "\n",
    "    # loop generating draws\n",
    "    for round_number in range(n_rounds):\n",
    "\n",
    "        # choosing arm for 10 next rounds\n",
    "        next_k_list = policy(k_list, reward_list, n_bandits, true_sigma)\n",
    "        \n",
    "        # drawing next 10 arms\n",
    "        # and recording information\n",
    "        for k in next_k_list:\n",
    "            reward, regret = gmab.draw(k)\n",
    "            k_list.append(k)\n",
    "            reward_list.append(reward)\n",
    "            regret_list.append(regret)\n",
    "\n",
    "    # returning choices, rewards and regrets\n",
    "    return k_list, reward_list, regret_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Now, let us implement the policies. All policies will use Thompson Sampling to make decisions, while the inference algorithms to estimate the posterior of expected rewards will be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS with Exact Inference\n",
    "\n",
    "We get the `scipy` object for the exact posterior and take 10 samples from it, for each bandit. Then, we choose the best bandit for each of the 10 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact policy\n",
    "class ExactPolicy:\n",
    "    \n",
    "    # initializing\n",
    "    def __init__(self):\n",
    "        \n",
    "        # nothing to do here\n",
    "        pass\n",
    "    \n",
    "    # choice of bandit\n",
    "    def choose_bandit(self, k_list, reward_list, n_bandits, true_sigma):\n",
    "        \n",
    "        # converting to arrays\n",
    "        k_list = np.array(k_list)\n",
    "        reward_list = np.array(reward_list)\n",
    "        \n",
    "        # exact inference object\n",
    "        infer = ExactGaussianInference(0.0, 1.0, true_sigma)\n",
    "        \n",
    "        # samples from the posterior for each bandit\n",
    "        bandit_post_samples = []\n",
    "        \n",
    "        # loop for each bandit to perform inference\n",
    "        for k in range(n_bandits):\n",
    "            \n",
    "            # filtering observation for this bandit\n",
    "            obs = reward_list[k_list == k]\n",
    "            \n",
    "            # performing inference and getting samples\n",
    "            samples = infer.get_posterior(obs).rvs(10)\n",
    "            bandit_post_samples.append(samples)\n",
    "                                \n",
    "        # returning bandit with best sample\n",
    "        return np.argmax(np.array(bandit_post_samples), axis=0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS with Metropolis-Hastings\n",
    "\n",
    "We take 120 samples, with a burn-in of 100 and a thinning of 2, so 10 samples remain, for each bandit. Then, we choose the best bandit for each of the 10 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact policy\n",
    "class MetropolisHastingsPolicy:\n",
    "    \n",
    "    # initializing\n",
    "    def __init__(self):\n",
    "        \n",
    "        # nothing to do here\n",
    "        pass\n",
    "    \n",
    "    # choice of bandit\n",
    "    def choose_bandit(self, k_list, reward_list, n_bandits, true_sigma):\n",
    "        \n",
    "        # converting to arrays\n",
    "        k_list = np.array(k_list)\n",
    "        reward_list = np.array(reward_list)\n",
    "        \n",
    "        # exact inference object\n",
    "        infer = MetropolisHastingsGaussianInference(0.0, 1.0, true_sigma, 0.10)\n",
    "        \n",
    "        # samples from the posterior for each bandit\n",
    "        bandit_post_samples = []\n",
    "        \n",
    "        # loop for each bandit to perform inference\n",
    "        for k in range(n_bandits):\n",
    "            \n",
    "            # filtering observation for this bandit\n",
    "            obs = reward_list[k_list == k]\n",
    "            \n",
    "            # performing inference and getting samples\n",
    "            samples = infer.get_posterior(obs, 120, 100, 2)\n",
    "            bandit_post_samples.append(samples)\n",
    "                                \n",
    "        # returning bandit with best sample\n",
    "        return np.argmax(np.array(bandit_post_samples), axis=0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS with Variational Inference\n",
    "\n",
    "We get the `scipy` object for the variational posterior and take 10 samples from it, for each bandit. Then, we choose the best bandit for each of the 10 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact policy\n",
    "class VariationalPolicy:\n",
    "    \n",
    "    # initializing\n",
    "    def __init__(self):\n",
    "        \n",
    "        # nothing to do here\n",
    "        pass\n",
    "    \n",
    "    # choice of bandit\n",
    "    def choose_bandit(self, k_list, reward_list, n_bandits, true_sigma):\n",
    "        \n",
    "        # converting to arrays\n",
    "        k_list = np.array(k_list)\n",
    "        reward_list = np.array(reward_list)\n",
    "        \n",
    "        # exact inference object\n",
    "        infer = VariationalGaussianInference(0.0, 1.0, true_sigma)\n",
    "        \n",
    "        # samples from the posterior for each bandit\n",
    "        bandit_post_samples = []\n",
    "        \n",
    "        # loop for each bandit to perform inference\n",
    "        for k in range(n_bandits):\n",
    "            \n",
    "            # filtering observation for this bandit\n",
    "            obs = reward_list[k_list == k]\n",
    "            \n",
    "            # performing inference and getting samples\n",
    "            samples = infer.get_posterior(obs).rvs(10)\n",
    "            bandit_post_samples.append(samples)\n",
    "                                \n",
    "        # returning bandit with best sample\n",
    "        return np.argmax(np.array(bandit_post_samples), axis=0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS with Bootstrapping\n",
    "\n",
    "We take 10 bootstrap samples, for each bandit. Then, we choose the best bandit for each of the 10 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact policy\n",
    "class BootstrapPolicy:\n",
    "    \n",
    "    # initializing\n",
    "    def __init__(self):\n",
    "        \n",
    "        # nothing to do here\n",
    "        pass\n",
    "    \n",
    "    # choice of bandit\n",
    "    def choose_bandit(self, k_list, reward_list, n_bandits, true_sigma):\n",
    "        \n",
    "        # converting to arrays\n",
    "        k_list = np.array(k_list)\n",
    "        reward_list = np.array(reward_list)\n",
    "        \n",
    "        # exact inference object\n",
    "        infer = BootstrapGaussianInference(0.0, 1.0, 0)\n",
    "        \n",
    "        # samples from the posterior for each bandit\n",
    "        bandit_post_samples = []\n",
    "        \n",
    "        # loop for each bandit to perform inference\n",
    "        for k in range(n_bandits):\n",
    "            \n",
    "            # filtering observation for this bandit\n",
    "            obs = reward_list[k_list == k]\n",
    "            \n",
    "            # performing inference and getting samples\n",
    "            samples = infer.get_posterior(obs, 10)\n",
    "            bandit_post_samples.append(samples)\n",
    "                                \n",
    "        # returning bandit with best sample\n",
    "        return np.argmax(np.array(bandit_post_samples), axis=0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running simulations\n",
    "\n",
    "To compare the algorithms, we run 100 different simulations for a game with 10 rounds (100 observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict to store policies and results\n",
    "simul_dict = {'exact': {'policy': ExactPolicy().choose_bandit,\n",
    "                        'regret': [],\n",
    "                        'choices': [],\n",
    "                        'rewards': []},\n",
    "              'metro': {'policy': MetropolisHastingsPolicy().choose_bandit,\n",
    "                        'regret': [],\n",
    "                        'choices': [],\n",
    "                        'rewards': []},\n",
    "              'var':   {'policy': VariationalPolicy().choose_bandit,\n",
    "                        'regret': [],\n",
    "                        'choices': [],\n",
    "                        'rewards': []}, \n",
    "              'boots': {'policy': BootstrapPolicy().choose_bandit,\n",
    "                        'regret': [],\n",
    "                        'choices': [],\n",
    "                        'rewards': []}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of simulations\n",
    "N_SIMULATIONS = 100\n",
    "\n",
    "# number of rounds\n",
    "N_ROUNDS = 10\n",
    "\n",
    "# loop for each algorithm\n",
    "for algo in simul_dict.keys():\n",
    "    \n",
    "    # loop for each simulation\n",
    "    for sim in tqdm(range(N_SIMULATIONS)):\n",
    "        \n",
    "        # running one game\n",
    "        k_list, reward_list, regret_list = run_gaussian_bandit(N_ROUNDS, simul_dict[algo]['policy'])\n",
    "        \n",
    "        # storing results\n",
    "        simul_dict[algo]['choices'].append(k_list)\n",
    "        simul_dict[algo]['rewards'].append(reward_list)\n",
    "        simul_dict[algo]['regret'].append(regret_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below compares the cumulative regret for all of our inference algorithms paired with Thompson sampling, in 100 simulation of 10 rounds of gaussian bandit play. The approximate inference techniques fared very well, in what I would call a technical draw between methods. Variational Inference and MCMC were much slower than exact inference and bootstrapping. As the algorithms were given 10 observations at each round, bootstrapping did not suffer with lack of prior specification. Really cool results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening figure\n",
    "fig = plt.figure(figsize=(10,5), dpi=150)\n",
    "\n",
    "# loop for each algorithm\n",
    "for algo in simul_dict.keys():\n",
    "    \n",
    "    # calculating average cumulative regret\n",
    "    avg_cum_regret = pd.DataFrame(np.array(simul_dict[algo]['regret'])).cumsum(axis=1).mean()\n",
    "    \n",
    "    # plotting regret line\n",
    "    plt.plot(avg_cum_regret, label=algo, linewidth=1.2)\n",
    "    \n",
    "# showing legend\n",
    "plt.legend()\n",
    "\n",
    "# title and axis labels\n",
    "plt.title('Comparison of approximate inference methods for Gaussian MAB', fontsize=14)\n",
    "plt.xlabel('Round'); plt.ylabel('Cumulative regret');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we explored and compared approximate inference techniques to solve a gaussian bandit problem with Thompson Sampling. The central issue in approximate bayesian inference is to compute the posterior distribution $p(z\\ |\\ x) = \\frac{p(x\\ |\\ z)\\cdot{}p(z)}{p(x)}$. In general, in order to do that, we need to avoid computing the model evidence $p(x)$, which is most of the times intractable. MCMC Sampling techniques try to approximate the posterior with an empirical distribution built thorugh monte carlo samples taken according to the unnormalized posterior $p(x\\ |\\ z)\\cdot{}p(z)$. Variational Inference, on the other hand, casts posterior inference as optimization, trying to find the variational distribution $q(z\\ ;\\ \\lambda)$ that better approximates the posterior. It does that by minimizing the divergence between $q(z\\ ;\\ \\lambda)$ and the unnormalized posterior $p(x\\ |\\ z)\\cdot{}p(z)$, which works the same as minimizing divergence with respect to the true posterior. Bootstrapping approximates the posterior with an empirical distribution calculated by taking many bootstrap samples of the data. In our case, specifically, it was also possible to calculate the exact posterior to serve as a baseline for comparison.\n",
    "\n",
    "Results were interesting. All approximate inference techniques did a good job approximating the exact posterior and showed similar performance in the gaussian bandit task. Bootstrapping was the most effcient, being faster than computing the exact posterior (as we only need to take one sample per action). VI and MCMC ran in similar time, as we need to only pass the burn-in to get the one sample per action for TS to work.\n",
    "\n",
    "Given the results observed, Bootstrapping seems to be a good candidate as a approximate inference method for bandits, as it also accomodates very compex posteriors with virtually no model development cost. However, we should be aware of its lack of prior specification, which could negatively impact performance due to lack of exploration in early rounds.\n",
    "\n",
    "What is your thought about this experiment? Feel free to comment! You can find the full code [here]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
